{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCZ Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "from rasterio import mask\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.enums import Resampling as ResamplingEnum\n",
    "from rasterio.windows import Window\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "\n",
    "import xml.dom.minidom\n",
    "\n",
    "import IPython.display as display\n",
    "import matplotlib\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.ticker as ticker\n",
    "from plotly import graph_objs as go\n",
    "\n",
    "import os\n",
    "from osgeo import gdal, ogr, gdalconst, gdal_array, osr\n",
    "\n",
    "from scipy.stats import mode\n",
    "from scipy.stats import linregress\n",
    "from scipy.ndimage import median_filter\n",
    "from shapely.geometry import box\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import functions and set auto-reload\n",
    "from functions_S2 import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_s2_date ='2023-11-17'\n",
    "\n",
    "formatted_date = sel_s2_date.replace('-', '')\n",
    "\n",
    "\n",
    "classification_method = 'Random Forest'\n",
    "sensor_w = 'Sentinel-2'\n",
    "\n",
    "output_path = r\"E:\\TESI\\LCZ_Geoinf_Proj\\MyCode\\Output\"\n",
    "input_path = r\"E:\\TESI\\LCZ_Geoinf_Proj\\MyCode\\Input\"\n",
    "\n",
    "nc_file_path = input_path + '\\Sentinel2_Summer.nc' #Netcdf file from which we will extract the .tiff file\n",
    "\n",
    "selected_s2_image = f'E:\\TESI\\LCZ_Geoinf_Proj\\MyCode\\Input\\S2_{formatted_date}_20m_masked_clip.tif'\n",
    "\n",
    "\n",
    "testing_set_path = f'E:\\TESI\\LCZ_Geoinf_Proj\\MyCode\\Output\\S2_{formatted_date}_20m_testing.tif'\n",
    "\n",
    "training_polygons = input_path + fr'\\training_set_{formatted_date}.gpkg'\n",
    "testing_polygons = input_path + fr'\\testing_set_{formatted_date}.gpkg'\n",
    "\n",
    "s2_meta = xml.dom.minidom.parse('E:\\TESI\\LCZ_Geoinf_Proj\\Dati_Esempio_Vavassori\\LCZ\\MTD_MSIL2A.xml') \n",
    "\n",
    "roi_new_path = f\"E:\\TESI\\LCZ_Geoinf_Proj\\MyCode\\Input\\S2_{formatted_date}_20m_masked_clip_2.tif\"\n",
    "\n",
    "cmm_folder = 'E:\\TESI\\BBOX\\Definitiva\\AOI.shp' # cmm_folder (str): path to the geopackage with the boundaries of the Metropolitan City of Milan\n",
    "\n",
    "attribute = 'LCZ' # Used to rasterize results\n",
    "projection = 32632 # Used to rasterize results and staking bands in a GEOTIFF from the netcdf\n",
    "ucp_path =  input_path + '/UCP_20m/'\n",
    "\n",
    "# OPTIONALLY\n",
    "#input_tiff = input_path + '\\S2_' + sel_s2_date.replace('-', '') + '_20m_all_bands_clip_NEW.tif' # Path to the file that has bands that needs to be reordered / path of folder including single bands that needs to be stacked\n",
    "#output_tiff = output_path + '\\S2_' + sel_s2_date.replace('-', '') + '_20m_all_bands_clip_NEW_reordered.tif' # Path and name of S2 with reordered bands / stacked bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Datacube to .tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube = xr.open_dataset(nc_file_path)\n",
    "print(datacube)\n",
    "ds = datacube.rename({\"B02\": \"bands\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = datacube.sel(time=sel_s2_date)\n",
    "print(subset)\n",
    "\n",
    "try:\n",
    "    datacube = xr.open_dataset(nc_file_path, engine=\"netcdf4\")\n",
    "except Exception as e:\n",
    "    print(\"Error reading NetCDF file:\", e)\n",
    "\n",
    "print(\"Available Variables in NetCDF:\", list(subset.data_vars.keys()))\n",
    "\n",
    "print(\"B02 Shape:\", subset[\"bands\"].shape)\n",
    "print(\"B02 Dimensions:\", subset[\"bands\"].dims)\n",
    "print(\"B02 Coordinates:\", subset[\"bands\"].coords)\n",
    "\n",
    "if \"band\" in subset[\"bands\"].dims:\n",
    "    b04_data = subset[\"bands\"].sel(band=\"B04\")\n",
    "    print(\"Extracted B04 Shape:\", b04_data.shape)\n",
    "else:\n",
    "    print(\"'band' dimension not found in 'bands'\")\n",
    "\n",
    "if \"band\" in subset[\"bands\"].dims:\n",
    "    # Iterate over all unique bands\n",
    "    for band_name in subset[\"bands\"].band.values:\n",
    "        # Extract data for the current band\n",
    "        band_data = subset[\"bands\"].sel(band=band_name)      \n",
    "        band_data.plot.imshow(cmap=\"viridis\")\n",
    "else:\n",
    "    print(\"'band' dimension not found in 'B02'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to hold the band data\n",
    "band_arrays = []\n",
    "\n",
    "# Extract and stack all bands\n",
    "for band_name in subset[\"bands\"].band.values:\n",
    "    band_data = subset[\"bands\"].sel(band=band_name).values  # Extract the band data as a numpy array\n",
    "    print(f\"Adding band: {band_name}\")  # Print the order\n",
    "    band_arrays.append(band_data)\n",
    "\n",
    "# Stack the bands into a 3D numpy array (each band as a slice)\n",
    "stacked_bands = np.stack(band_arrays, axis=0)  # Shape: (num_bands, lat, lon)\n",
    "\n",
    "# Get metadata information for the TIFF file (e.g., spatial reference)\n",
    "transform = from_origin(subset.lon.values[0], subset.lat.values[0], abs(subset.lat.values[1] - subset.lat.values[0]), abs(subset.lon.values[1] - subset.lon.values[0]))\n",
    "\n",
    "# Create the output TIFF file\n",
    "with rio.open( \n",
    "    input_tiff,\n",
    "    'w', \n",
    "    driver='GTiff', \n",
    "    count=stacked_bands.shape[0],  # Number of bands\n",
    "    width=stacked_bands.shape[2],  # Number of columns (lon)\n",
    "    height=stacked_bands.shape[1],  # Number of rows (lat)\n",
    "    dtype=stacked_bands.dtype,  # Data type (e.g., float32 or float64)\n",
    "    crs= projection,  # Coordinate reference system (can be changed if needed)\n",
    "    transform=transform  # Geospatial transform\n",
    ") as dst:\n",
    "    # Write each band to the .tiff file\n",
    "    #for i in range(stacked_bands.shape[0]):\n",
    "    for i, band_name in enumerate(subset[\"bands\"].band.values):\n",
    "        dst.write(stacked_bands[i], i+1)  # Band indices start from 1 in rasterio\n",
    "        dst.set_band_description(i+1, band_name)  # ✅ Set band name\n",
    "\n",
    "print(\"✅ Saved the stacked bands as a .tiff file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reorder Bands and Save File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TIFF file saved with corrected band order.\n"
     ]
    }
   ],
   "source": [
    "# Current and correct band order\n",
    "current_order = [\"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B11\", \"B12\", \"B8A\"]  # Incorrect\n",
    "correct_order = [\"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B11\", \"B12\"]  # Correct\n",
    "\n",
    "# Compute the reordering indices\n",
    "reorder_indices = [current_order.index(band) for band in correct_order]\n",
    "\n",
    "# Open the input TIFF\n",
    "with rasterio.open(input_tiff) as src:\n",
    "    meta = src.meta.copy()  # Copy metadata\n",
    "    meta.update(count=len(correct_order))  # Update number of bands if needed\n",
    "\n",
    "    # Read all bands and reorder them\n",
    "    bands = [src.read(i + 1) for i in reorder_indices]  # Read and reorder bands\n",
    "\n",
    "    # Write new TIFF with correct order\n",
    "    with rasterio.open(output_tiff, 'w', **meta) as dst:\n",
    "        for i, band_data in enumerate(bands):\n",
    "            dst.write(band_data, i + 1)  # Write bands in new order\n",
    "            dst.set_band_description(i + 1, correct_order[i])  # Set correct names\n",
    "\n",
    "print(\"✅ TIFF file saved with corrected band order.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(output_tiff) as dataset:\n",
    "    for i in range(1, dataset.count + 1):\n",
    "        print(f\"✅ Band {i}: {dataset.descriptions[i-1]}\")\n",
    "        band = dataset.read(i)  # Read band data\n",
    "\n",
    "        # Flatten and remove NaNs\n",
    "        valid_pixels = band[~np.isnan(band)].flatten()\n",
    "\n",
    "        # Compute the 90th percentile threshold\n",
    "        p90 = np.percentile(valid_pixels, 90)\n",
    "\n",
    "        # Filter out extreme values (keep values below 90th percentile)\n",
    "        filtered_pixels = valid_pixels[valid_pixels <= p90]\n",
    "\n",
    "        # Compute statistics\n",
    "        min_val = np.min(filtered_pixels)\n",
    "        max_val = np.max(filtered_pixels)\n",
    "        mean_val = np.mean(filtered_pixels)\n",
    "\n",
    "        # Compute mode (most frequent value)\n",
    "        mode_val = mode(filtered_pixels, keepdims=False).mode\n",
    "\n",
    "        print(f\"✅ {dataset.descriptions[i-1]} - Min: {min_val}, Max: {max_val}, Mean: {mean_val}, Mode: {mode_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[492.7, 559.8, 664.6, 704.1, 740.5, 782.8, 864.7, 1613.7, 2202.4]\n"
     ]
    }
   ],
   "source": [
    "wvl_s = get_prisma_s2_wvl(prisma_meta = 0, s2_meta = s2_meta)\n",
    "print(wvl_s)\n",
    "wvl_s = [492.7, 559.8, 664.6, 704.1, 740.5, 782.8, 832.8, 864.7, 1613.7, 2202.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(selected_s2_image) as src_s:\n",
    "    data_s = src_s.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_threshold = 1e-8\n",
    "data = data_s[~np.all(data_s <= band_threshold, axis=(1,2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signature_widgets(selected_s2_image, wvl = 0, wvl_s = wvl_s, data = data, data_s = data_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training sample spectral signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = {\n",
    "    2: ['Compact mid-rise', '#D10000'],\n",
    "    3: ['Compact low-rise', '#CD0000'],\n",
    "    5: ['Open mid-rise', '#FF6600'],\n",
    "    6: ['Open low-rise', '#FF9955'],\n",
    "    8: ['Large low-rise', '#BCBCBC'],\n",
    "    101: ['Dense trees', '#006A00'],\n",
    "    102: ['Scattered trees', '#00AA00'],\n",
    "    104: ['Low plants', '#B9DB79'],\n",
    "    105: ['Bare rock or paved', '#545454'],\n",
    "    106: ['Bare soil or sand', '#FBF7AF'],\n",
    "    107: ['Water', '#6A6AFF']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(selected_s2_image) as src:\n",
    "    print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, m, shapes = plot_training_samples(training_polygons, cmm_folder, legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_sign_s, spectral_sign_std_s = compute_spectral_signature(selected_s2_image, legend, shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_LCZ_names = [value[0] for value in legend.values()]\n",
    "selected_classes = [key for key, value in legend.items() if value[0] in selected_LCZ_names]\n",
    "print(selected_LCZ_names)\n",
    "print(selected_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interactive_spectral_sign(wvl=0, wvl_s=wvl_s, spectral_sign=0, spectral_sign_s=spectral_sign_s, legend=legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training sample spectral signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing, m_testing, shapes_testing = plot_training_samples(training_polygons, cmm_folder, legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_sign_test_s, spectral_sign_test_std_s = compute_spectral_signature(selected_s2_image, legend, shapes_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of S2 imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(selected_s2_image) as src:\n",
    "    # Read RGB bands (B4=Red, B3=Green, B2=Blue)\n",
    "    img = src.read(indexes=[4, 3, 2]).astype('float32')  # 1-based indexing\n",
    "    nodata = src.nodata\n",
    "\n",
    "# Replace nodata values or any NaNs with 0\n",
    "img[np.isnan(img)] = 0\n",
    "if nodata is not None:\n",
    "    img[img == nodata] = 0\n",
    "\n",
    "# Normalize by the 99th percentile to reduce outlier impact\n",
    "percentile = np.percentile(img, 99)\n",
    "img = np.clip(img / percentile, 0, 1)\n",
    "\n",
    "# Convert from (3, H, W) to (H, W, 3) for matplotlib\n",
    "img = np.transpose(img, (1, 2, 0))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img)\n",
    "plt.title(\"Sentinel-2 RGB Composite\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_LCZ_path = training_area(sel_s2_date, legend, training_polygons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rasterize training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = gdal.GetDriverByName('GTiff')\n",
    "if driver is None:\n",
    "    raise ValueError(\"GTiff driver is not available.\")\n",
    "\n",
    "import os\n",
    "if not os.path.isdir(os.path.dirname(output_path)):\n",
    "    raise ValueError(f\"Output directory does not exist: {os.path.dirname(output_path)}\")\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_training_file_name = output_path + '\\S2_' + sel_s2_date.replace('-', '') + '_20m_training.tif' # Save here rasterized image\n",
    "rasterized_result = rasterize_training(selected_s2_image, vector_LCZ_path, output_training_file_name, attribute, projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = prisma_bbox(selected_s2_image, sel_s2_date, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_s2 = mask_s2_image(selected_s2_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperv_new_path = ucp_path + 'IMD.tif' # imperviousness\n",
    "perc_build_new_path = ucp_path + 'BSF.tif' #building fraction\n",
    "svf_new_path = ucp_path + 'SVF.tif'\n",
    "canopy_height_new_path = ucp_path + 'TCH.tif'\n",
    "buildings_new_path = ucp_path + 'BH.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproj_match(infile, match, outfile):\n",
    "    \"\"\"Reproject a file to match the shape, alignment, extent, and projection of an existing raster.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    infile : (string) path to input file to reproject\n",
    "    match : (string) path to raster with desired shape, alignment, extent, and projection\n",
    "    outfile : (string) path to output file tif\n",
    "    \"\"\"\n",
    "    # Open the input file\n",
    "    with rasterio.open(infile) as src:\n",
    "        src_transform = src.transform\n",
    "        src_crs = src.crs\n",
    "\n",
    "        # Open the match file\n",
    "        with rasterio.open(match) as match_raster:\n",
    "            match_crs = match_raster.crs\n",
    "            match_transform = match_raster.transform\n",
    "            match_width = match_raster.width\n",
    "            match_height = match_raster.height\n",
    "\n",
    "        # Update the metadata to match the `match` raster\n",
    "        dst_meta = src.meta.copy()\n",
    "        dst_meta.update({\n",
    "            \"crs\": match_crs,\n",
    "            \"transform\": match_transform,\n",
    "            \"width\": match_width,\n",
    "            \"height\": match_height,\n",
    "        })\n",
    "\n",
    "        # Create the output file\n",
    "        with rasterio.open(outfile, \"w\", **dst_meta) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src_transform,\n",
    "                    src_crs=src_crs,\n",
    "                    dst_transform=match_transform,\n",
    "                    dst_crs=match_crs,\n",
    "                    resampling=Resampling.nearest,\n",
    "                )\n",
    "\n",
    "\n",
    "reproj_match(perc_build_new_path, selected_s2_image, ucp_path + 'building_fraction_20m_align.tif')\n",
    "reproj_match(imperv_new_path, selected_s2_image, ucp_path + 'imperviousness_20m_align.tif')\n",
    "reproj_match(svf_new_path, selected_s2_image, ucp_path + 'SVF_20m_align.tif')\n",
    "reproj_match(canopy_height_new_path, selected_s2_image, ucp_path + 'canopy_height_20m_align.tif')\n",
    "reproj_match(buildings_new_path, selected_s2_image, ucp_path + 'building_height_20m_align.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperv = open_layer(ucp_path + 'canopy_height_20m_align.tif', mask_s2)\n",
    "perc_build = open_layer(ucp_path + 'building_fraction_20m_align.tif', mask_s2)\n",
    "svf = open_layer(ucp_path + 'SVF_20m_align.tif', mask_s2)\n",
    "canopy_height = open_layer( ucp_path + 'canopy_height_20m_align.tif', mask_s2)\n",
    "buildings = open_layer(ucp_path + 'building_height_20m_align.tif', mask_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ucl(imperv, perc_build, svf, canopy_height, buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_area = gpd.read_file(bbox)\n",
    "\n",
    "print(output_training_file_name)\n",
    "img, roi = clip_training_sample(selected_s2_image, output_training_file_name, sel_s2_date, study_area, roi_new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperv, perc_build, svf, canopy_height, buildings, roi = check_layers_dimension(imperv, perc_build, svf, canopy_height, buildings, roi, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.dstack((imperv, perc_build, svf, canopy_height, buildings, img))\n",
    "print(f\"The stacked array shape is --> {img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.unique(roi[roi > 0])\n",
    "print(f'The training data include {labels.size} classes: {labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = img[roi > 0, :] \n",
    "y = roi[roi > 0]\n",
    "print(f'X matrix size: {X.shape}')\n",
    "print(f'y array size: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function performs hyperparameter tuning for the selected classification algorithm, and returns the best hyperparameter. The selection is done by computing the accuracy score:\n",
    "\n",
    "$ {Accuracy Score} = {(TP+TN)\\over(TP+FN+TN+FP)}$\n",
    "\n",
    "where $TP$ and $TN$ are true positives/negatives, $FP$ abd $FN$ are false positives/negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params, best_score, cv_results = parameter_tuning(classification_method, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params\n",
    "best_score\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'criterion': best_params['criterion'], 'max_features': best_params['max_features'], 'n_estimators': best_params['n_estimators']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, clc = classification(classification_method, best_params, X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(\n",
    "    clc, X_test, y_test, n_repeats=10, random_state=0, n_jobs=2\n",
    ")\n",
    "feature_names = [\"Imp\", \"BSF\", \"SVF\", \"CH\", \"BH\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B11\", \"B12\"]\n",
    "forest_importances = pd.Series(result.importances_mean, index=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
    "ax.set_title(\"Feature importances using permutation on full model\")\n",
    "ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clc.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clc.estimators_], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [f\"feature {i}\" for i in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Accuracy assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Classified image filtering and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_classified_map(img, clc, X, selected_s2_image, classification_method, sel_s2_date, output_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.nan_to_num(img)\n",
    "\n",
    "print(f'Using {classification_method}')\n",
    "# reshape into long 2d array (nrow * ncol, nband) for classification\n",
    "new_shape = (img.shape[0] * img.shape[1], img.shape[2])\n",
    "\n",
    "img_as_array = img[:, :, :X.shape[1]].reshape(new_shape)\n",
    "print('Reshaped from {o} to {n}'.format(o=img.shape,n=img_as_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now predict for each pixel\n",
    "class_prediction = clc.predict(img_as_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape our classification map\n",
    "class_prediction = class_prediction.reshape(img[:, :, 0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCZ classification accuracy assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Classification accuracy on testing samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Import testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = {\n",
    "    2: ['Compact mid-rise', '#D10000'],\n",
    "    3: ['Compact low-rise', '#CD0000'],\n",
    "    5: ['Open mid-rise', '#FF6600'],\n",
    "    6: ['Open low-rise', '#FF9955'],\n",
    "    8: ['Large low-rise', '#BCBCBC'],\n",
    "    101: ['Dense trees', '#006A00'],\n",
    "    102: ['Scattered trees', '#00AA00'],\n",
    "    104: ['Low plants', '#B9DB79'],\n",
    "    105: ['Bare rock or paved', '#545454'],\n",
    "    106: ['Bare soil or sand', '#FBF7AF'],\n",
    "    107: ['Water', '#6A6AFF']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing, m, shapes = plot_training_samples(testing_polygons, cmm_folder, legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_LCZ_path = testing_area(sel_s2_date, legend, testing_polygons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rasterize testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_testing_file_name = output_path + '\\S2_' + sel_s2_date.replace('-', '') + '_20m_testing.tif' # Save here rasterized image\n",
    "rasterized_result = rasterize_training(selected_s2_image, vector_LCZ_path, output_testing_file_name, attribute, projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = prisma_bbox(selected_s2_image, sel_s2_date, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_prisma = mask_prisma_image(selected_s2_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Import the classified image to be assessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Selected classification method: {classification_method}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_image_path = output_path + '\\classified_' + classification_method + '_' + sel_s2_date.replace('-', '') + '_medianfilter_20m.tif' # Classified image path\n",
    "classified_image = rasterio.open(classified_image_path)\n",
    "print(f\"Selected image shape: {classified_image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Assess classification accuracy on testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, confusion, report, report_df = print_accuracy_s2(classification_method, sel_s2_date, sel_s2_date, legend, classified_image_path, testing_set_path )\n",
    "print(sel_s2_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
