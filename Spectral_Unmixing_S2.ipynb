{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPECTRAL UNMIXING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.transform import rowcol\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optionally mask S2 images with SCL band if it has not alrady been done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = \"2023-11-17\"\n",
    "folder_path = r\"E:\\TESI\\OpenEO\\Output\\AllBands\"\n",
    "output_folder = r\"E:\\TESI\\OpenEO\\Output\\MaskedMaps\"\n",
    "nodata_value = -99999 # Nodata value to use for masked pixels\n",
    "bands = [\"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B11\", \"B12\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clouds, Cloud Shadows and Cyrrus Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scl_path = rf\"E:\\TESI\\OpenEO\\Output\\SCL_20m_{target_date}.tiff\"\n",
    "\n",
    "# --- Load the SCL band ---\n",
    "with rasterio.open(scl_path) as scl_ds:\n",
    "    scl_data = scl_ds.read(1)\n",
    "\n",
    "# Cloud mask: True where NOT cloudy, False where cloudy\n",
    "valid_mask = ~np.isin(scl_data, [3, 8, 9, 10])\n",
    "\n",
    "# --- Process each band ---\n",
    "for band in bands:\n",
    "    input_path = os.path.join(folder_path, f\"Sentinel2_{band}_{target_date}.tiff\")\n",
    "    output_path = os.path.join(output_folder, f\"Sentinel2_{band}_{target_date}_masked.tiff\")\n",
    "\n",
    "    print(f\"Processing {band}...\")\n",
    "\n",
    "    with rasterio.open(input_path) as src:\n",
    "        band_data = src.read(1).astype(np.int32)  # Promote to avoid overflow\n",
    "        profile = src.profile\n",
    "\n",
    "    # Apply the mask: set nodata_value where cloudy\n",
    "    masked_band = np.where(valid_mask, band_data, nodata_value)\n",
    "\n",
    "    # Update profile\n",
    "    profile.update(dtype=rasterio.int32, nodata=nodata_value)\n",
    "\n",
    "    # Ensure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        dst.write(masked_band, 1)\n",
    "\n",
    "    print(f\"Saved masked band: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a daframe containing the spectral signature values for each point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = \"2023-11-17\" # Date you are interested in\n",
    "folder_path   = r\"E:\\TESI\\OpenEO\\Output\\MaskedMaps\" # Folder containing all Bands\n",
    "bands         = [\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B11\",\"B12\"] # Bands you are interested in\n",
    "gpkg_path     = rf\"E:\\TESI\\Spectral_Unmixing_Geoinf_Proj\\Unmixing_QGIS\\Output\\Final_points_{target_date}.gpkg\" # Path to the geopakage containing training points\n",
    "nan_values = -99999 # Nodata value to use for masked pixels\n",
    "output_path = rf\"E:\\TESI\\Spectral_Unmixing_Geoinf_Proj\\Python_Output\\fraction_maps_multiband_masked_{target_date}.tif\" #Folder where fraction maps will be saved in\n",
    "reference_raster =f\"E:\\TESI\\OpenEO\\Output\\MaskedMaps\\Sentinel2_B02_{target_date}_masked.tiff\" # Reference raster to copy spatial metadata, could be a any Band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Stack Raster Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_arrays = []\n",
    "band_names  = []\n",
    "\n",
    "for band in bands:\n",
    "    pattern = os.path.join(folder_path, f\"Sentinel2_{band}_{target_date}_masked.tiff\") # Naming convention of your S2 images -- Change it based on your image name convention\n",
    "    matches = glob.glob(pattern) # Images matching the pattern\n",
    "    if not matches:\n",
    "        raise FileNotFoundError(f\"No file found for band {band!r} on {target_date}\")\n",
    "    tif_path = matches[0]\n",
    "    \n",
    "    with rasterio.open(tif_path) as src:\n",
    "        if not band_arrays:\n",
    "            # Capture spatial metadata from chosen image\n",
    "            transform = src.transform\n",
    "            print(\"Transform:\", transform)\n",
    "            crs       = src.crs\n",
    "            print(\"Raster CRS:\", crs)\n",
    "            height, width = src.height, src.width\n",
    "        \n",
    "        arr = src.read(1)  # (rows, cols)\n",
    "        band_arrays.append(arr)\n",
    "        band_names.append(band)\n",
    "\n",
    "# stack into (n_bands, rows, cols)\n",
    "stacked_bands = np.stack(band_arrays, axis=0)\n",
    "height, width = stacked_bands.shape[1:]  # rows, cols\n",
    "\n",
    "# Get proper bounds from the first raster (assuming all images have the same spatial extent)\n",
    "with rasterio.open(tif_path) as src:\n",
    "    bounds = src.bounds  # BoundingBox(left, bottom, right, top)\n",
    "\n",
    "# LOAD POINTS AND REPROJECT\n",
    "gdf = gpd.read_file(gpkg_path)\n",
    "gdf = gdf.to_crs(crs)  # ensure points are in the same CRS as the images\n",
    "\n",
    "# EXTRACT SPECTRA AT POINT LOCATIONS\n",
    "samples = []\n",
    "for idx, pt in gdf.iterrows(): #iterate over each point as rows in a table, pt is a row including fid, endmember, endmember_class\n",
    "    x, y = pt.geometry.x, pt.geometry.y\n",
    "    #extracts values form the row\n",
    "    fid           = idx\n",
    "    endmember     = pt[\"endmember\"]\n",
    "    endmember_cls = pt[\"endmember_class\"]\n",
    "    \n",
    "    # convert to row, col\n",
    "    row, col = rowcol(transform, x, y)\n",
    "    #col, row = rowcol(transform, x, y)\n",
    "    col = int(col)\n",
    "    row = int(row)\n",
    "    \n",
    "    # check bounds\n",
    "    if not (0 <= row < stacked_bands.shape[1] and 0 <= col < stacked_bands.shape[2]):\n",
    "        print(f\"⚠️  Point {fid} at ({x:.0f},{y:.0f}) outside raster bounds; skipping\")\n",
    "        continue\n",
    "    \n",
    "    spectrum = stacked_bands[:, row, col]  # length = len(bands)\n",
    "    \n",
    "    # build dict: {\"B02\":val, ..., \"B12\":val, \"endmember\":..., \"endmember_class\":...}\n",
    "    sample = {band_names[i]: float(spectrum[i]) for i in range(len(band_names))}\n",
    "    sample[\"fid\"]             = fid\n",
    "    sample[\"endmember\"]       = endmember\n",
    "    sample[\"endmember_class\"] = endmember_cls\n",
    "    samples.append(sample)\n",
    "\n",
    "# TRANSFORM TO DATAFRAME\n",
    "endmember_df = pd.DataFrame(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a syntetic training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Pure Spectra for Each Endmember Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume endmember_df has columns B02…B12 and endmember_class (integers 1–7)\n",
    "spectra_by_class = defaultdict(list)\n",
    "\n",
    "for _, row in endmember_df.iterrows():\n",
    "    clsId = row[\"endmember_class\"]\n",
    "    spectrum = row[bands].values.astype(float)  # array of length = \"number of bands\"\n",
    "    spectra_by_class[clsId].append(spectrum)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "for clsId in spectra_by_class:\n",
    "    spectra_by_class[clsId] = np.stack(spectra_by_class[clsId], axis=0)\n",
    "    print(f\"Class {clsId} has {spectra_by_class[clsId].shape[0]} pure spectra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create a Synthetic Dataset\n",
    "Given a class, make N mixed spectra by combining:\n",
    "A random pure target spectrum\n",
    "A random pure background spectrum (from any other class)\n",
    "A random fraction f ∈ [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_synthetic_dataset(target_cls, spectra_by_class, n_samples=1000):\n",
    "    X = []  # mixed spectra, a n band vector (n = number of bands) shape: (n_samples, n_bands)\n",
    "    y = []  # target fractions, float from 0 to 1 shape: (n_samples,)\n",
    "\n",
    "    target_specs = spectra_by_class[target_cls] # pure spectra for the class we focus on\n",
    "    # build a background pool composed of all spectra from all other classes\n",
    "    bg_specs = np.vstack([\n",
    "        specs for cls, specs in spectra_by_class.items() if cls != target_cls\n",
    "    ])\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        # pick one random pure target and one random pure background\n",
    "        t = target_specs[np.random.randint(len(target_specs))] # pick a random target spectrum\n",
    "        b = bg_specs[np.random.randint(len(bg_specs))] # pick a random background spectrum\n",
    "        f = np.random.rand()  # fraction of target float from 0 to 1\n",
    "\n",
    "        mix = f * t + (1 - f) * b #synthetic mixed spectrum resulting from a linear combination, with high values of f the resulting mix will be close to che pure spectrum\n",
    "        X.append(mix)\n",
    "        y.append(f)\n",
    "\n",
    "    return np.vstack(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train One Regressor Per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for cls in spectra_by_class:\n",
    "    Xc, yc = make_synthetic_dataset(cls, spectra_by_class, n_samples=2000)\n",
    "    rf = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=42) # oob_score: (Out-Of-Bag) computed by testing on the samples the tree didn't see during training (usually around 1/3) || random_state=42 for reproducibility (42 because it is the answer of everything)\n",
    "    rf.fit(Xc, yc) # train the model on the synthetic data\n",
    "    print(f\"Trained RF for class {cls}, OOB score: {rf.oob_score_:.3f}\") # 1.0: perfect; 0.0: worst than random\n",
    "    models[cls] = rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply each model to every pixel in the stacked image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!WARNING!!!   --    THIS PROCEDURE IS COMPUTATIONALLY INTENSIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_pixels = stacked_bands.reshape(10, -1).T  # shape (n_pixels, 10)\n",
    "# Create mask of valid pixels (True where all bands are NOT -99999)\n",
    "valid_mask = np.all(stacked_bands != nan_values, axis=0)  # shape: (height, width)\n",
    "flat_valid_mask = valid_mask.flatten()\n",
    "valid_pixels = flat_pixels[flat_valid_mask]\n",
    "\n",
    "fraction_maps = {} # dictionary with 1 image corresponding to each class\n",
    "for cls, rf in models.items():\n",
    "    preds = rf.predict(valid_pixels)          # (n_pixels,)\n",
    "    preds = np.clip(preds, 0, 1) # Clamp predictions between 0 and 1\n",
    "    # reshape back to image\n",
    "    #frac_map = preds.reshape(stacked_bands.shape[1:]) #convert results in the original shape\n",
    "    frac_map = np.full(valid_mask.shape, np.nan, dtype=np.float32)\n",
    "    frac_map[valid_mask] = preds\n",
    "\n",
    "    fraction_maps[cls] = frac_map\n",
    "    print(f\"Predicted fraction map for class {cls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enforce constrains\n",
    "All classes sum to 1 in each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all fraction maps into (n_classes, rows, cols)\n",
    "cls_list = sorted(fraction_maps.keys()) #list of all class labels\n",
    "stacked_f = np.stack([fraction_maps[c] for c in cls_list], axis=0) #each \"layer\" in the 3D array is a class, and each pixel has a fraction value for that class.\n",
    "\n",
    "# normalize along axis=0 per-pixel enforcing the constrain\n",
    "s = np.sum(stacked_f, axis=0, keepdims=True)\n",
    "s[s == 0] = 1 # avoids division-by-zero if a pixel has 0 for all classes\n",
    "normalized = stacked_f / s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOTTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Each Fraction Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the class labels in cls_list\n",
    "n_classes = normalized.shape[0]\n",
    "fig, axes = plt.subplots(1, n_classes, figsize=(4 * n_classes, 5))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    im = ax.imshow(normalized[i], cmap='viridis', vmin=0, vmax=1)\n",
    "    ax.set_title(f\"Class {cls_list[i]}\")\n",
    "    ax.axis('off')\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving all bands in a single .tiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(reference_raster) as ref: # just a reference raster \n",
    "    meta = ref.meta.copy()\n",
    "    transform = ref.transform\n",
    "    crs = ref.crs\n",
    "\n",
    "# Update metadata for multi-band output\n",
    "meta.update({\n",
    "    \"count\": len(cls_list),           # number of bands = number of classes\n",
    "    \"dtype\": \"float32\",               # fraction values\n",
    "    \"driver\": \"GTiff\"\n",
    "})\n",
    "\n",
    "# Save the multi-band raster\n",
    "with rasterio.open(output_path, \"w\", **meta) as dst:\n",
    "    for i, cls in enumerate(cls_list):\n",
    "        dst.write(normalized[i].astype(\"float32\"), i + 1)  # rasterio is 1-indexed\n",
    "        dst.set_band_description(i + 1, f\"Class_{cls}\")\n",
    "\n",
    "print(f\"✅ Saved multi-band fraction map to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check .tif file obtained with the code against the .tif file obtained with the plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date =  \"2023-11-17\"\n",
    "path_plugin = rf\"E:\\TESI\\Spectral_Unmixing_Geoinf_Proj\\Unmixing_QGIS\\Output\\Final_Class_Fraction_Layer_Masked_{target_date}.tif\" # path to the image generated via plugin\n",
    "path_code = rf\"E:\\TESI\\Spectral_Unmixing_Geoinf_Proj\\Python_Output\\fraction_maps_multiband_masked_{target_date}.tif\" # path to the image generated via code\n",
    "\n",
    "# Class labels\n",
    "class_names = [\n",
    "    \"Shingle\", \"Metal\", \"Asphalt/Concrete\", \"Sand/Bare Soil\",\n",
    "    \"Tall Vegetation\", \"Water\", \"Grass Low Vegetation\"\n",
    "]\n",
    "\n",
    "# Thresholds for confident classification\n",
    "#NOTE: a pixel is defined as confidentially classified if the class with the highest value inside the pixel has value higher then the \"dominant_thresh\" and\n",
    "# if the second highest value inside the pixel has value lower than the \"second_thresh\"\n",
    "dominant_thresh = 0.7\n",
    "second_thresh = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the results against the one obtained trough the EnMap-Box3 QGIS plugin.\n",
    "Both maps are creted using a RF as model.\n",
    "We will refer to the 2 images as \"Plugin\" and \"Coded\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Map Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(path_plugin) as src1:\n",
    "    plugin_data = src1.read()  # shape (bands, rows, cols)\n",
    "\n",
    "with rasterio.open(path_code) as src2:\n",
    "    code_data = src2.read()    # shape (bands, rows, cols)\n",
    "\n",
    "print(\"Plugin shape:\", plugin_data.shape)\n",
    "print(\"Code shape:\", code_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed color scaling\n",
    "vmin, vmax = 0, 1 #Set min and max values so that it will be fixed between the 2 images\n",
    "diff_vmin, diff_vmax = -0.1, 0.1 # Only pixels with differences bigger than ±0.1 will hit the extreme colors. Otherwise, the pixel will stay stay in a soft color range.\n",
    "\n",
    "n_classes = plugin_data.shape[0]\n",
    "\n",
    "# Create a big figure: rows = number of classes, cols = 3 (plugin, code, diff)\n",
    "fig, axs = plt.subplots(n_classes, 3, figsize=(15, 5 * n_classes))\n",
    "\n",
    "# If only 1 class, axs will not be 2D, fix that\n",
    "if n_classes == 1:\n",
    "    axs = np.expand_dims(axs, axis=0)\n",
    "\n",
    "for cls_idx in range(n_classes):\n",
    "    class_name = class_names[cls_idx] if cls_idx < len(class_names) else f\"Class {cls_idx+1}\"\n",
    "\n",
    "    # Mask NaN values\n",
    "    plugin_masked = np.ma.masked_invalid(plugin_data[cls_idx])\n",
    "    code_masked = np.ma.masked_invalid(code_data[cls_idx])\n",
    "    diff_masked = np.ma.masked_invalid(code_data[cls_idx] - plugin_data[cls_idx])\n",
    "\n",
    "    # Plot\n",
    "    axs[cls_idx, 0].imshow(plugin_masked, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "    axs[cls_idx, 0].set_title(f\"Plugin - {class_name}\")\n",
    "\n",
    "    axs[cls_idx, 1].imshow(code_masked, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "    axs[cls_idx, 1].set_title(f\"Coded - {class_name}\")\n",
    "\n",
    "    axs[cls_idx, 2].imshow(diff_masked, cmap='bwr', vmin=diff_vmin, vmax=diff_vmax) # negative = blue, positive = red\n",
    "    axs[cls_idx, 2].set_title(\"Difference (zoomed)\")\n",
    "\n",
    "    for ax in axs[cls_idx]:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics for each class\n",
    "for cls_idx in range(n_classes):\n",
    "    class_name = class_names[cls_idx] if cls_idx < len(class_names) else f\"Class {cls_idx+1}\"\n",
    "    plugin_masked = np.ma.masked_invalid(plugin_data[cls_idx])\n",
    "    code_masked = np.ma.masked_invalid(code_data[cls_idx])\n",
    "    diff_masked = np.ma.masked_invalid(code_data[cls_idx] - plugin_data[cls_idx])\n",
    "\n",
    "    plugin_min, plugin_max = plugin_masked.min(), plugin_masked.max()\n",
    "    code_min, code_max = code_masked.min(), code_masked.max()\n",
    "    diff_min, diff_max = diff_masked.min(), diff_masked.max()\n",
    "\n",
    "    print(f\"{class_name} (Class {cls_idx + 1})\")\n",
    "    print(f\"  Plugin    min/max: {plugin_min:.3f}, {plugin_max:.3f}\")\n",
    "    print(f\"  Coded min/max: {code_min:.3f}, {code_max:.3f}\")\n",
    "    print(f\"  Difference range : {diff_min:.3f}, {diff_max:.3f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Value Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference\n",
    "diff = code_data - plugin_data\n",
    "\n",
    "# Masking NaN values in the difference and absolute difference\n",
    "diff_masked = np.ma.masked_invalid(diff)\n",
    "abs_diff = np.abs(diff_masked)\n",
    "\n",
    "# Compute the mean absolute difference per class, ignoring NaNs\n",
    "mean_abs_diff_per_class = np.ma.mean(abs_diff, axis=(1, 2))\n",
    "\n",
    "# Print the results\n",
    "for i, diff_val in enumerate(mean_abs_diff_per_class):\n",
    "    print(f\"Class {i+1} - Mean Absolute Difference: {diff_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(code_data.shape[0]):\n",
    "    flat_code = code_data[i].flatten()\n",
    "    flat_plugin = plugin_data[i].flatten()\n",
    "\n",
    "    # Mask NaN values in both the flattened arrays\n",
    "    valid_mask = ~np.isnan(flat_code) & ~np.isnan(flat_plugin)\n",
    "\n",
    "    # Apply the mask to exclude NaN values\n",
    "    flat_code_valid = flat_code[valid_mask]\n",
    "    flat_plugin_valid = flat_plugin[valid_mask]\n",
    "    \n",
    "    # Compute the Pearson correlation coefficient, ignoring NaNs\n",
    "    if len(flat_code_valid) > 1:  # Check to avoid insufficient data for correlation\n",
    "        corr = np.corrcoef(flat_code_valid, flat_plugin_valid)[0, 1]\n",
    "        print(f\"Class {i+1} - Correlation: {corr:.4f}\")\n",
    "    else:\n",
    "        print(f\"Class {i+1} - Not enough valid data for correlation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(code_data.shape[0]): # loop over each class\n",
    "    flat_code = code_data[i].flatten()\n",
    "    flat_plugin = plugin_data[i].flatten()\n",
    "\n",
    "    # Mask NaN values in both arrays\n",
    "    valid_mask = ~np.isnan(flat_code) & ~np.isnan(flat_plugin)\n",
    "\n",
    "    # Apply the mask to remove NaN values\n",
    "    flat_code_valid = flat_code[valid_mask]\n",
    "    flat_plugin_valid = flat_plugin[valid_mask]\n",
    "    \n",
    "    # Compute the Pearson correlation coefficient\n",
    "    if len(flat_code_valid) > 1:  # Check if there's enough valid data\n",
    "        corr = np.corrcoef(flat_code_valid, flat_plugin_valid)[0, 1]\n",
    "    else:\n",
    "        corr = np.nan  # If not enough valid data, set correlation to NaN\n",
    "    \n",
    "    # Create scatter plot\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(flat_plugin_valid, flat_code_valid, s=1, alpha=0.5, color='royalblue')\n",
    "    plt.plot([0, 1], [0, 1], 'r--', label='Ideal match')\n",
    "    plt.title(f\"{class_names[i]} - Scatter Plot\\nCorrelation: {corr:.4f}\")\n",
    "    plt.xlabel(\"Plugin pixel values\")\n",
    "    plt.ylabel(\"Your code pixel values\")\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average, Maximum and Minimum Difference Between the Plugin and the Code Only on \"Confidently Classified\" Pixels\n",
    "NOTE: a pixel is deifned as \"Confidentially Classified\" if the class with the highest value inside the pixel has value higher then the \"dominant_thresh\" and if the the second highest value inside the pixel has value lower than the \"second_thresh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To collect absolute differences between plugin and code results\n",
    "abs_diffs = []\n",
    "\n",
    "rows, cols = plugin_data.shape[1], plugin_data.shape[2]\n",
    "\n",
    "# Loop through all pixels\n",
    "for row in range(rows):\n",
    "    for col in range(cols):\n",
    "        pixel = plugin_data[:, row, col]\n",
    "        top_two = np.sort(pixel)[-2:]\n",
    "\n",
    "        if top_two[-1] > dominant_thresh and top_two[-2] < second_thresh:\n",
    "            dominant_class = np.argmax(pixel)\n",
    "\n",
    "            plugin_val = plugin_data[dominant_class, row, col]\n",
    "            code_val = code_data[dominant_class, row, col]\n",
    "\n",
    "            # Skip if either plugin_val or code_val is NaN\n",
    "            if np.isnan(plugin_val) or np.isnan(code_val):\n",
    "                continue\n",
    "\n",
    "            abs_diffs.append(abs(plugin_val - code_val))\n",
    "\n",
    "# Convert to NumPy array for stats\n",
    "abs_diffs = np.array(abs_diffs)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Number of clearly defined pixels: {len(abs_diffs)}\")\n",
    "print(f\"Mean absolute difference: {abs_diffs.mean():.4f}\")\n",
    "print(f\"Max absolute difference: {abs_diffs.max():.4f}\")\n",
    "print(f\"Min absolute difference: {abs_diffs.min():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute and Percentage Mismatches among \"Confidently Classified\" Pixels\n",
    "\n",
    "NOTE: a pixel is defined as \"Confidentially Classified\" if the class with the highest value inside the pixel has value higher then the \"dominant_thresh\" and if the second highest value inside the pixel has value lower than the \"second_thresh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counters\n",
    "total_confident = 0\n",
    "mismatch_count = 0\n",
    "\n",
    "rows, cols = plugin_data.shape[1], plugin_data.shape[2]\n",
    "total_pixels = rows * cols\n",
    "\n",
    "# Loop through all pixels\n",
    "for row in range(rows):\n",
    "    for col in range(cols):\n",
    "        pixel_plugin = plugin_data[:, row, col]\n",
    "        \n",
    "        # Skip if there are NaN values in the plugin pixel\n",
    "        if np.any(np.isnan(pixel_plugin)):\n",
    "            continue\n",
    "        \n",
    "        top_two = np.sort(pixel_plugin)[-2:]\n",
    "\n",
    "        # Check if this is a clearly defined pixel\n",
    "        if top_two[-1] > dominant_thresh and top_two[-2] < second_thresh:\n",
    "            total_confident += 1\n",
    "\n",
    "            # Get dominant class from both plugin and code\n",
    "            plugin_class = np.argmax(pixel_plugin)\n",
    "            \n",
    "            # Skip if there are NaN values in the code data\n",
    "            if np.isnan(code_data[plugin_class, row, col]):\n",
    "                continue\n",
    "\n",
    "            code_class = np.argmax(code_data[:, row, col])\n",
    "\n",
    "            if plugin_class != code_class:\n",
    "                mismatch_count += 1\n",
    "\n",
    "# Calculate percentages\n",
    "percent_confident = (total_confident / total_pixels) * 100 if total_pixels > 0 else 0.0\n",
    "percent_mismatch = (mismatch_count / total_confident) * 100 if total_confident > 0 else 0.0\n",
    "\n",
    "# Print results\n",
    "print(f\"Percentage of confidently classified pixels: {percent_confident:.2f}%\")\n",
    "print(f\"Number of mismatches: {mismatch_count}\")\n",
    "print(f\"Percentage of mismatches among confident pixels: {percent_mismatch:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms Comparison\n",
    "NOTE: the plugin set classes present whith a low percentage (close to 0), directly to 0. This does not happen in my code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(class_names)\n",
    "\n",
    "# Create a figure with subplots: 1 row per class\n",
    "fig, axs = plt.subplots(n_classes, 1, figsize=(8, 4 * n_classes), sharex=True)\n",
    "\n",
    "# If only 1 class, axs will not be an array\n",
    "if n_classes == 1:\n",
    "    axs = [axs]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    ax = axs[i]\n",
    "\n",
    "    # Flatten and filter values\n",
    "    code_vals = code_data[i].flatten()\n",
    "    plugin_vals = plugin_data[i].flatten()\n",
    "    plugin_vals = plugin_vals[plugin_vals >= 0]  # Remove invalid values\n",
    "\n",
    "    # Normalize histograms to show percentage\n",
    "    weights_code = np.ones_like(code_vals) / len(code_vals) * 100\n",
    "    weights_plugin = np.ones_like(plugin_vals) / len(plugin_vals) * 100\n",
    "\n",
    "    # Plot\n",
    "    ax.hist(code_vals, bins=50, alpha=0.5, label=\"Code\", range=(0, 1), weights=weights_code)\n",
    "    ax.hist(plugin_vals, bins=50, alpha=0.5, label=\"Plugin\", range=(0, 1), weights=weights_plugin)\n",
    "\n",
    "    # Labels and formatting\n",
    "    ax.set_title(f\"{class_names[i]} - Value Distribution\")\n",
    "    ax.set_ylabel(\"Percentage of Pixels (%)\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "    ax.legend()\n",
    "\n",
    "# Common x-label for all\n",
    "axs[-1].set_xlabel(\"Fraction Value\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_points_path = rf\"E:\\TESI\\Spectral_Unmixing_Geoinf_Proj\\Unmixing_QGIS\\Output\\NEW_VALIDATION_points_{target_date}.gpkg\" #Will be renamed to \"Testing Points\" in the future.\n",
    "plugin_tif      = rf\"E:\\TESI\\Spectral_Unmixing_Geoinf_Proj\\Unmixing_QGIS\\Output\\Final_Class_Fraction_Layer_Masked_{target_date}.tif\"\n",
    "code_tif        = rf\"E:\\TESI\\Spectral_Unmixing_Geoinf_Proj\\Python_Output\\fraction_maps_multiband_masked_{target_date}.tif\"\n",
    "\n",
    "# In this case, thresholds are set to so all pixels will be considered\n",
    "dominant_thresh = 0.0 \n",
    "second_thresh   = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "Considering Dominant OR Non-Dominant Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LOAD TESTING POINTS\n",
    "gdf = gpd.read_file(testing_points_path)\n",
    "truth_col = \"endmember_class\"\n",
    "\n",
    "# OPEN RASTERS\n",
    "src_plug = rasterio.open(plugin_tif)\n",
    "src_code = rasterio.open(code_tif)\n",
    "\n",
    "# SAMPLE FRACTIONS & BUILD RECORDS\n",
    "records = []\n",
    "cls_list = sorted(range(1, src_plug.count + 1))  # [1,2,…,n_classes]\n",
    "\n",
    "for idx, pt in gdf.iterrows():\n",
    "    x, y = pt.geometry.x, pt.geometry.y\n",
    "    truth = pt[truth_col]\n",
    "\n",
    "    # sample returns arrays of length = band count\n",
    "    plugin_vals = np.array(list(src_plug.sample([(x, y)]))[0])\n",
    "    code_vals   = np.array(list(src_code.sample([(x, y)]))[0])\n",
    "\n",
    "    def classify(vals):\n",
    "        # find top two fractions\n",
    "        top2 = np.sort(vals)[-2:]\n",
    "        if top2[-1] > dominant_thresh and top2[-2] < second_thresh: # Only if the top value is > \"dominant_thresh\" and the second is < \"second_thresh\"\n",
    "            pred_idx = np.argmax(vals)\n",
    "            return cls_list[pred_idx], True\n",
    "        else:\n",
    "            return None, False\n",
    "\n",
    "    plug_pred, plug_conf = classify(plugin_vals)\n",
    "    code_pred, code_conf = classify(code_vals)\n",
    "\n",
    "    records.append({\n",
    "        \"fid\": idx,\n",
    "        \"truth\": truth,\n",
    "        # plugin result\n",
    "        \"plug_pred\": plug_pred,\n",
    "        \"plug_conf\": plug_conf,\n",
    "        \"plug_correct\": plug_conf and (plug_pred == truth), # Correct if the model is confident, and the predicted class matches the true class exactly.\n",
    "        # code result\n",
    "        \"code_pred\": code_pred,\n",
    "        \"code_conf\": code_conf,\n",
    "        \"code_correct\": code_conf and (code_pred == truth),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# 4) OVERALL METRICS\n",
    "total = len(df)\n",
    "\n",
    "def summarize(method):\n",
    "    conf       = df[f\"{method}_conf\"].sum()\n",
    "    correct    = df[f\"{method}_correct\"].sum()\n",
    "    incorrect  = conf - correct\n",
    "    non_conf   = total - conf\n",
    "    return pd.Series({\n",
    "        \"TotalPts\": total,\n",
    "        \"Confident\": conf,\n",
    "        \"  Correct\": correct,\n",
    "        \"  Incorrect\": incorrect,\n",
    "        \"NonConfident\": non_conf,\n",
    "        \"PctConfident\": conf/total*100,\n",
    "        \"PctCorrect|Conf\": correct/conf*100 if conf>0 else np.nan,\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"Plugin\": summarize(\"plug\"),\n",
    "    \"Code\":   summarize(\"code\"),\n",
    "}).T\n",
    "\n",
    "print(\"\\n=== OVERALL SUMMARY ===\")\n",
    "print(summary)\n",
    "\n",
    "# PER-CLASS METRICS\n",
    "per_class = []\n",
    "for cls in cls_list:\n",
    "    sub = df[df[\"truth\"] == cls]\n",
    "    total_cls = len(sub)\n",
    "    for method in (\"plug\", \"code\"):\n",
    "        conf      = sub[f\"{method}_conf\"].sum()\n",
    "        correct   = sub[f\"{method}_correct\"].sum()\n",
    "        incorrect = conf - correct\n",
    "        per_class.append({\n",
    "            \"Class\": cls,\n",
    "            \"Method\": method,\n",
    "            \"TotalPts\": total_cls,\n",
    "            \"Confident\": conf,\n",
    "            \"Correct\":   correct,\n",
    "            \"Incorrect\": incorrect,\n",
    "            \"NonConf\":   total_cls - conf,\n",
    "            \"PctConf\":   conf/total_cls*100 if total_cls>0 else np.nan,\n",
    "            \"PctCorr|Conf\": correct/conf*100 if conf>0 else np.nan,\n",
    "        })\n",
    "\n",
    "pc_df = pd.DataFrame(per_class)\n",
    "print(\"\\n=== PER-CLASS SUMMARY ===\")\n",
    "print(pc_df.pivot(index=\"Class\", columns=\"Method\", \n",
    "                  values=[\"TotalPts\",\"Confident\",\"Correct\",\"PctCorr|Conf\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all class labels\n",
    "cls_list = sorted(df['truth'].unique())\n",
    "\n",
    "def print_confusion(method_name, pred_col, conf_col):\n",
    "    # Select only the rows where the method was confident\n",
    "    mask = df[conf_col]\n",
    "    y_true = df.loc[mask, 'truth']\n",
    "    y_pred = df.loc[mask, pred_col]\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=cls_list)\n",
    "    cm_df = pd.DataFrame(cm, index=cls_list, columns=cls_list)\n",
    "\n",
    "    print(f\"\\n=== Confusion Matrix for {method_name} (confident only) ===\")\n",
    "    print(\"Rows = true class, Columns = predicted class\\n\")\n",
    "    print(cm_df)\n",
    "    print()\n",
    "\n",
    "# Plugin confusion\n",
    "print_confusion(\"Plugin\", pred_col=\"plug_pred\", conf_col=\"plug_conf\")\n",
    "\n",
    "# Code confusion\n",
    "print_confusion(\"Code\",   pred_col=\"code_pred\", conf_col=\"code_conf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
